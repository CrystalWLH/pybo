{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# PyBo's Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Running the tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pybo import BoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instanciate the tokenizer with the 'POS' profile (see [profile documentation](this.file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Trie...\n",
      "Time: 2.5575690269470215\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BoTokenizer('POS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a random text in Tibetan language,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_str = '༆ ཤི་བཀྲ་ཤིས་  tr བདེ་་ལེ གས། བཀྲ་ཤིས་བདེ་ལེགས་༡༢༣ཀཀ མཐའི་རྒྱ་མཚོར་གནས་པའི་ཉས་ཆུ་འཐུང་།། །།'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what information can be derived from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output is a <class 'list'>.\n",
      "The constituting elements are <class 'pybo.token.Token'>s.\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenizer.tokenize(input_str)\n",
    "print(f'The output is a {type(tokens)}.\\nThe constituting elements are {type(tokens[0])}s.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Non Tibetan tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First thing, I see there is non-Tibetan stuff in the middle of the input string. Let's see how I can detect it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"tr\", token number 4, is not Tibetan.\n",
      "this starts at 15th character in the input and spans 2 characters\n"
     ]
    }
   ],
   "source": [
    "for n, token in enumerate(tokens):\n",
    "    if token.type == 'non-bo':\n",
    "        content = token.content\n",
    "        print(f'\"{content}\", token number {n+1}, is not Tibetan.')\n",
    "        start = token.start\n",
    "        length = token.len\n",
    "        print(f'this starts at {start}th character in the input and spans {length} characters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Tokens that are not words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is there any Tibetan punctuation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"༆\", token number 1, is a punctuation token.\n",
      "\"།\", token number 6, is a punctuation token.\n",
      "\"།། \", token number 19, is a punctuation token.\n",
      "\"།།\", token number 20, is a punctuation token.\n"
     ]
    }
   ],
   "source": [
    "for n, token in enumerate(tokens):\n",
    "    if token.type == 'punct':\n",
    "        content = token.content\n",
    "        print(f'\"{content}\", token number {n+1}, is a punctuation token.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How are the Tibetan digits treated?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"༡༢༣\", token number 9, is a numeral.\n"
     ]
    }
   ],
   "source": [
    "for n, token in enumerate(tokens):\n",
    "    if token.type == 'num':\n",
    "        content = token.content\n",
    "        print(f'\"{content}\", token number {n+1}, is a numeral.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. The attributes of tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t \"type\" attribute\n",
      "\n",
      "punct\t: token 1(\"༆\") has Tibetan content, but it is not a word\n",
      "syl\t: token 2(\" ཤི་\")\n",
      "syl\t: token 3(\"བཀྲ་ཤིས་  \")\n",
      "non-bo\t: token 4(\"tr\") does not have Tibetan content.\n",
      "syl\t: token 5(\" བདེ་་ལེ གས\")\n",
      "punct\t: token 6(\"།\") has Tibetan content, but it is not a word\n",
      "syl\t: token 7(\" བཀྲ་ཤིས་\")\n",
      "syl\t: token 8(\"བདེ་ལེགས་\")\n",
      "num\t: token 9(\"༡༢༣\") has Tibetan content, but it is not a word\n",
      "syl\t: token 10(\"ཀཀ མཐའི་\")\n",
      "syl\t: token 11(\"རྒྱ་མཚོ\")\n",
      "syl\t: token 12(\"ར་\")\n",
      "syl\t: token 13(\"གནས་པ\")\n",
      "syl\t: token 14(\"འི་\")\n",
      "syl\t: token 15(\"ཉ\")\n",
      "syl\t: token 16(\"ས་\")\n",
      "syl\t: token 17(\"ཆུ་\")\n",
      "syl\t: token 18(\"འཐུང་\")\n",
      "punct\t: token 19(\"།། \") has Tibetan content, but it is not a word\n",
      "punct\t: token 20(\"།།\") has Tibetan content, but it is not a word\n"
     ]
    }
   ],
   "source": [
    "print('\\t \"type\" attribute\\n')\n",
    "for n, token in enumerate(tokens):\n",
    "    print(token.type, end='\\t: ')\n",
    "    if token.type == 'syl':\n",
    "        print(f'token {n+1}(\"{token.content}\")')\n",
    "    elif token.type == 'non-bo':\n",
    "        print(f'token {n+1}(\"{token.content}\") does not have Tibetan content.')\n",
    "    else:\n",
    "        print(f'token {n+1}(\"{token.content}\") has Tibetan content, but it is not a word')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "there is a bug in token 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
